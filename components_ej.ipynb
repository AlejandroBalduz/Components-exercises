{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Component Modelling exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will practice key Python concepts by completing a series of code snippets. Certain parts of the code are left incomplete, marked with `# TODO: COMPLETE`. Your task is to fill in these sections correctly to make the program work as intended.\n",
    "\n",
    "Work carefully through each step, test your code as you go, and make sure you understand why your solution works. This hands-on practice will help solidify your understanding of Python syntax, logic, and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null imputer component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NullImputer:\n",
    "    def __init__(self, strategy=\"mean\"):\n",
    "        assert strategy in [\"mean\", \"median\", \"most_frequent\"], \\\n",
    "            \"Strategy must be one of: 'mean', 'median', 'most_frequent'\"\n",
    "        self.strategy = strategy\n",
    "        self.fill_values = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise TypeError(\"NullImputer expects a pandas DataFrame\")\n",
    "\n",
    "        for col in X.columns:\n",
    "            if self.strategy == \"mean\":\n",
    "                self.fill_values[col] = X[col].mean()\n",
    "            elif self.strategy == \"median\":\n",
    "                self.fill_values[col] = X[col].median()\n",
    "            elif self.strategy == \"most_frequent\":\n",
    "                self.fill_values[col] = X[col].mode().dropna()\n",
    "                self.fill_values[col] = self.fill_values[col].iloc[0] if not self.fill_values[col].empty else None\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if not self.fill_values:\n",
    "            raise ValueError(\"You must call 'fit' before 'transform'\")\n",
    "\n",
    "        return X.fillna(self.fill_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop null component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropNull:\n",
    "    \"\"\"\n",
    "    Transformer that removes columns with a proportion of missing values above a given threshold.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    threshold : float, default=0.2\n",
    "        Maximum allowed proportion of missing values in a column.\n",
    "        Columns exceeding this proportion will be dropped during transformation.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    col_drop : list\n",
    "        List of column names to be removed after calling `fit`.\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fit(X, y=None):\n",
    "        Identifies columns that exceed the missing value threshold and stores them in `col_drop`.\n",
    "\n",
    "    transform(X):\n",
    "        Drops columns listed in `col_drop` from `X`.\n",
    "        Raises a ValueError if `fit` has not been called first.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: COMPLETE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaler component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scaler:\n",
    "    def __init__(self, method=\"standard\"):\n",
    "        assert method in [\"standard\", \"minmax\", \"robust\"], \\\n",
    "            \"method must be one of: 'standard', 'minmax', 'robust'\"\n",
    "        self.method = method\n",
    "        self.params = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            raise TypeError(\"Scaler expects a pandas DataFrame\")\n",
    "\n",
    "        if self.method == \"standard\":\n",
    "            std = X.std()\n",
    "            std[std == 0] = 1  # avoid zero division\n",
    "\n",
    "            self.params[\"mean\"] = X.mean()\n",
    "            self.params[\"std\"] = std\n",
    "\n",
    "        elif self.method == \"minmax\":\n",
    "            # TODO: COMPLETE\n",
    "            pass\n",
    "\n",
    "        elif self.method == \"robust\":\n",
    "            # TODO: COMPLETE\n",
    "            pass\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if not self.params:\n",
    "            raise ValueError(\"You must call 'fit' before 'transform'\")\n",
    "\n",
    "        if self.method == \"standard\":\n",
    "            return (X - self.params[\"mean\"]) / self.params[\"std\"]\n",
    "        elif self.method == \"minmax\":\n",
    "            # TODO: COMPLETE\n",
    "            pass\n",
    "        elif self.method == \"robust\":\n",
    "            # TODO: COMPLETE\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor model and Pipeline implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EstimatorStep:\n",
    "    def __init__(self, estimator):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    # Note: transform not implemented; .predict will be used in pipeline\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    def __init__(self, steps):\n",
    "        self.steps = steps\n",
    "        self.named_steps = dict(steps)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        for i, (name, step) in enumerate(self.steps):\n",
    "            is_last = (i == len(self.steps)-1)\n",
    "            if hasattr(step, 'transform') and not is_last:\n",
    "                step.fit(X, y)\n",
    "                X = step.transform(X)\n",
    "            else:\n",
    "                # Last step or not transform method (model)\n",
    "                step.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Applies only if preprocessing (Has transform)\n",
    "        for i, (name, step) in enumerate(self.steps):\n",
    "            is_last = (i == len(self.steps)-1)\n",
    "            if hasattr(step, 'transform') and not is_last:\n",
    "                X = step.transform(X)\n",
    "        return X\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_proc = self.transform(X)\n",
    "        last_step = self.steps[-1][1]\n",
    "        return last_step.predict(X_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Config: choose model ----\n",
    "MODEL = \"rf\"  # \"rf\" (RandomForest) or \"dt\" (DecisionTree)\n",
    "\n",
    "if MODEL == \"rf\":\n",
    "    estimator = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1)\n",
    "elif MODEL == \"dt\":\n",
    "    estimator = DecisionTreeRegressor(random_state=42)\n",
    "else:\n",
    "    raise ValueError(\"MODEL should be 'rf' or 'dt'\")\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ----------- Load data -----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. ----------- Load data -----------\n",
    "housing = fetch_california_housing(as_frame=True)\n",
    "data = housing.frame\n",
    "\n",
    "# 1.1. ----------- Making dataset realistic -----------\n",
    "n_rows = data.shape[0]\n",
    "\n",
    "# Insert ~10% of NaNs in 'AveRooms' and 'HouseAge'\n",
    "for col in [\"AveRooms\", \"HouseAge\"]:\n",
    "    missing_indices = np.random.choice(n_rows, size=int(0.1 * n_rows), replace=False)\n",
    "    data.loc[missing_indices, col] = np.nan\n",
    "\n",
    "# Constant column\n",
    "data[\"constant_col\"] = 42\n",
    "\n",
    "# Almost all NaNs column\n",
    "data[\"mostly_null\"] = np.nan\n",
    "data.loc[10:20, \"mostly_null\"] = 1\n",
    "\n",
    "print('\\n', data.head(), '\\n')\n",
    "print(data.dtypes, '\\n')\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. ----------- Split features and target -----------\n",
    "X = data.drop(columns=[\"MedHouseVal\"])\n",
    "y = data[\"MedHouseVal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ----------- Train/Test Split (before any preprocessing!) -----------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f'\\nInstances of train: {len(X_train)}')\n",
    "print(f'Instances of test: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ----------- Pipeline -----------\n",
    "pipeline = Pipeline([\n",
    "    (\"dropnull\", DropNull(threshold=0.2)),\n",
    "    (\"imputer\", NullImputer(strategy=\"median\")),\n",
    "    (\"scaler\", Scaler(method=\"standard\")),\n",
    "    (\"model\", EstimatorStep(estimator))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. ----------- pipeline fit (preproc + model) -----------\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Check drop null\n",
    "dropnull_component = dict(pipeline.steps)[\"dropnull\"]\n",
    "if hasattr(dropnull_component, \"col_drop\"):\n",
    "    print(\"\\nDropped columns by DropNull:\", dropnull_component.col_drop)\n",
    "\n",
    "# We can check params of the steps\n",
    "scaler_component = dict(pipeline.steps)[\"scaler\"]\n",
    "print(\"\\nCalculated mean in scaler fit:\")\n",
    "print(scaler_component.params[\"mean\"])\n",
    "print(\"\\nCalculated STD in scaler fit:\")\n",
    "print(scaler_component.params[\"std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. ----------- Predictions and metrics using pipeline -----------\n",
    "y_pred_train = pipeline.predict(X_train)\n",
    "y_pred_test  = pipeline.predict(X_test)\n",
    "\n",
    "rmse_train = root_mean_squared_error(y_train, y_pred_train)\n",
    "rmse_test  = root_mean_squared_error(y_test,  y_pred_test)\n",
    "\n",
    "print(f\"\\n[Model trained: {MODEL}]\")\n",
    "print(f\"R2 Train: {r2_score(y_train, y_pred_train):.3f} | RMSE Train: {rmse_train:.3f}\")\n",
    "print(f\"R2 Test : {r2_score(y_test,  y_pred_test ):.3f} | RMSE Test : {rmse_test:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
